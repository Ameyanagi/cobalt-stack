# Improve Chat User Experience

## Why

Frontend has hardcoded model list that drifts from backend, all sessions start as "New Chat" requiring manual naming, and chat feature is hidden from main navigation.

## What Changes

- Frontend fetches models from existing `GET /api/v1/chat/models` endpoint instead of static config
- New backend endpoint `PATCH /api/v1/chat/sessions/{id}/generate-title` for automatic title generation
- Session titles automatically generated by LLM after first assistant response
- Chat navigation links added to application header and landing page

## Impact

- Affected specs: `chat`, `frontend-navigation` (new)
- Affected code:
  - `frontend/src/config/models.ts` - remove static model list
  - `frontend/src/components/chat/chat-container.tsx` - fetch models, trigger title generation
  - `frontend/src/app/page.tsx` - add chat navigation links
  - `backend/src/application/chat/generate_session_title.rs` - new use case
  - `backend/src/handlers/chat/generate_title.rs` - new handler

## Scope

### In Scope
- Backend endpoint already exists (`GET /api/v1/chat/models`) - wire to frontend
- Add backend endpoint for title generation (`PATCH /api/v1/chat/sessions/{id}/generate-title`)
- Update frontend to consume models endpoint instead of static config
- Add chat navigation links to header and landing page
- Auto-trigger title generation after first assistant message

### Out of Scope
- Manual title editing (already exists via `update_title`)
- Model search/filtering UI
- Title generation for existing sessions (only applies to new conversations)
- Custom title generation prompts

## Dependencies

- Existing `/api/v1/chat/models` endpoint (already implemented)
- LLM provider factory for title generation
- Frontend chat components
- Navigation components

## Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Title generation fails | Session keeps "New Chat" title | Fail silently, log error, keep default title |
| Title generation slow | Delays user experience | Run async, don't block message display |
| Backend models change | Frontend shows stale list | Fetch on mount and cache for session |
| LLM generates inappropriate title | Poor UX | Add length limits, character filtering |

## Timeline Estimate

- Backend model filtering: 2 hours (mostly frontend changes)
- Auto title generation: 4 hours (backend endpoint + frontend integration)
- Navigation links: 1 hour (component updates)
- Testing: 2 hours (E2E flows)
- **Total**: ~9 hours

## Related Changes

- Builds on `add-llm-chatbot` change (already in progress)
- Prepares for future model management features
- Improves discoverability for chat feature

## Alternative Approaches Considered

### 1. Client-Side Model Filtering
**Rejected**: Would still require backend source of truth, adds unnecessary complexity

### 2. User-Provided Titles
**Rejected**: Poor UX, users ignore this step, all sessions remain "New Chat"

### 3. Summarize Full Conversation
**Rejected**: First message usually sufficient, wastes tokens, slower

### 4. Modal for Chat Access
**Rejected**: Adds friction, simple link is cleaner
