/**
 * LLM Models Configuration
 *
 * This configuration mirrors the backend models.toml for UI display
 */

import type { LlmModel, ModelGroup } from '@/types/chat';

export const DEFAULT_MODEL_ID = 'llama-3.3-70b';

export const AVAILABLE_MODELS: LlmModel[] = [
  // SambaNova Models
  {
    id: 'llama-3.3-70b',
    name: 'Llama 3.3 70B Instruct',
    provider: 'SambaNova',
    description: 'Latest Meta Llama model with excellent performance',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: false,
    cost_per_million_input_tokens: 0.6,
    cost_per_million_output_tokens: 0.6,
    tags: ['fast', 'balanced', 'recommended'],
    recommended_for: ['general', 'conversation', 'analysis'],
  },
  {
    id: 'llama-3.2-90b',
    name: 'Llama 3.2 90B Vision Instruct',
    provider: 'SambaNova',
    description: 'Multimodal model with vision capabilities',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: false,
    cost_per_million_input_tokens: 0.6,
    cost_per_million_output_tokens: 0.6,
    tags: ['vision', 'multimodal'],
    recommended_for: ['image-analysis', 'multimodal'],
  },
  {
    id: 'llama-3.1-405b',
    name: 'Llama 3.1 405B Instruct',
    provider: 'SambaNova',
    description: 'Most powerful Llama model for complex tasks',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: false,
    cost_per_million_input_tokens: 5.0,
    cost_per_million_output_tokens: 15.0,
    tags: ['powerful', 'complex'],
    recommended_for: ['complex-reasoning', 'advanced-analysis'],
  },

  // Azure OpenAI Models
  {
    id: 'gpt-4o',
    name: 'GPT-4o',
    provider: 'Azure OpenAI',
    description: 'Most capable GPT-4 model with multimodal support',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 5.0,
    cost_per_million_output_tokens: 15.0,
    tags: ['powerful', 'multimodal', 'function-calling'],
    recommended_for: ['complex-tasks', 'function-calling'],
  },
  {
    id: 'gpt-4o-mini',
    name: 'GPT-4o Mini',
    provider: 'Azure OpenAI',
    description: 'Affordable and fast GPT-4 variant',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 0.15,
    cost_per_million_output_tokens: 0.6,
    tags: ['fast', 'affordable'],
    recommended_for: ['general', 'quick-tasks'],
  },
  {
    id: 'gpt-4-turbo',
    name: 'GPT-4 Turbo',
    provider: 'Azure OpenAI',
    description: 'Enhanced GPT-4 with improved performance',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 10.0,
    cost_per_million_output_tokens: 30.0,
    tags: ['powerful', 'function-calling'],
    recommended_for: ['complex-reasoning', 'function-calling'],
  },
  {
    id: 'gpt-35-turbo',
    name: 'GPT-3.5 Turbo',
    provider: 'Azure OpenAI',
    description: 'Fast and efficient model for everyday tasks',
    context_window: 16385,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 0.5,
    cost_per_million_output_tokens: 1.5,
    tags: ['fast', 'affordable'],
    recommended_for: ['general', 'quick-tasks'],
  },
  {
    id: 'llama-70b',
    name: 'Meta Llama 3.1 70B Instruct',
    provider: 'Azure AI',
    description: 'Open-source Llama model via Azure',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: false,
    cost_per_million_input_tokens: 0.6,
    cost_per_million_output_tokens: 0.6,
    tags: ['balanced', 'open-source'],
    recommended_for: ['general', 'conversation'],
  },
  {
    id: 'llama-405b',
    name: 'Meta Llama 3.1 405B Instruct',
    provider: 'Azure AI',
    description: 'Largest Llama model for complex tasks',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: false,
    cost_per_million_input_tokens: 5.0,
    cost_per_million_output_tokens: 15.0,
    tags: ['powerful', 'open-source'],
    recommended_for: ['complex-reasoning'],
  },

  // Azure Grok Models
  {
    id: 'grok-4',
    name: 'Grok 4',
    provider: 'Azure AI (xAI)',
    description: "xAI's most capable model with advanced reasoning",
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 5.0,
    cost_per_million_output_tokens: 15.0,
    tags: ['powerful', 'reasoning', 'grok'],
    recommended_for: ['complex-reasoning', 'advanced-analysis'],
  },
  {
    id: 'grok-4-fast-reasoning',
    name: 'Grok 4 Fast Reasoning',
    provider: 'Azure AI (xAI)',
    description: 'Optimized Grok 4 for faster reasoning tasks',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 5.0,
    cost_per_million_output_tokens: 15.0,
    tags: ['fast', 'reasoning', 'grok'],
    recommended_for: ['quick-reasoning', 'analysis'],
  },
  {
    id: 'grok-4-fast-non-reasoning',
    name: 'Grok 4 Fast',
    provider: 'Azure AI (xAI)',
    description: 'Fastest Grok variant for general tasks',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: false,
    cost_per_million_input_tokens: 2.0,
    cost_per_million_output_tokens: 6.0,
    tags: ['fast', 'grok'],
    recommended_for: ['general', 'quick-tasks'],
  },

  // GPT-5 Codex
  {
    id: 'gpt-5-codex',
    name: 'GPT-5 Codex',
    provider: 'Azure AI',
    description: 'Advanced code generation and understanding model',
    context_window: 128000,
    max_output_tokens: 4096,
    supports_streaming: true,
    supports_function_calling: true,
    cost_per_million_input_tokens: 10.0,
    cost_per_million_output_tokens: 30.0,
    tags: ['code', 'advanced', 'gpt-5'],
    recommended_for: ['code-generation', 'code-review', 'debugging'],
  },
];

export const MODEL_GROUPS: ModelGroup[] = [
  {
    name: 'Fast Models',
    description: 'Quick responses for everyday tasks',
    models: ['llama-3.3-70b', 'gpt-4o-mini', 'gpt-35-turbo', 'grok-4-fast-non-reasoning'],
  },
  {
    name: 'Powerful Models',
    description: 'Advanced capabilities for complex reasoning',
    models: ['llama-3.1-405b', 'gpt-4o', 'gpt-4-turbo', 'grok-4', 'llama-405b'],
  },
  {
    name: 'Code Generation',
    description: 'Specialized for programming tasks',
    models: ['gpt-5-codex'],
  },
  {
    name: 'Grok Models',
    description: "xAI's Grok models with advanced reasoning",
    models: ['grok-4', 'grok-4-fast-reasoning', 'grok-4-fast-non-reasoning'],
  },
  {
    name: 'Multimodal',
    description: 'Models with vision and image understanding',
    models: ['llama-3.2-90b', 'gpt-4o'],
  },
];
